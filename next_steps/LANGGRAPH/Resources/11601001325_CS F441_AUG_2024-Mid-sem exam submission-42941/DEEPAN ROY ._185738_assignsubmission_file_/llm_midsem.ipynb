{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am working on keeping separate nodes for:\n",
    "1. Class extraction,\n",
    "2. Rubric extraction,\n",
    "3. Initial evaluation,\n",
    "4. Evaluation review,\n",
    "5. Marks extraction, and\n",
    "6. Marks calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool for marks calculation\n",
    "\n",
    "# @tool\n",
    "def sum_marks(marks):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Return sum of sequence of marks.\n",
    "    \n",
    "    Args:\n",
    "        marks (str): Comma separated string of marks\n",
    "        \n",
    "    Returns:\n",
    "        sum_of_marks (int): Sum of marks\"\"\"\n",
    "    \n",
    "    sum_of_marks = sum(int(mark) for mark in marks)\n",
    "    return sum_of_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def parse_classes(state):\n",
    "    \"\"\"\n",
    "    Parses given student Java code submission and extracts individual classes. Also parses given model Java code and extracts individual classes.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages. Agent response should look like: (List[str], List[str]): Tuple where first element is list of strings from student submission where each string is a separate class, and second element is list of strings from model code where each string is a separate class.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---PARSE CLASSES---\")\n",
    "\n",
    "    # LLM\n",
    "    messages = state[\"messages\"]\n",
    "    model_1 = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "    response = model_1.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def parse_rubric(state):\n",
    "    \"\"\"\n",
    "    Parses given rubric and separate out rubric elements for different classes (if there is more than 1 class).\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages. Agent response should look like: List[str]: List of strings where each string is the rubric for a certain class.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---PARSE RUBRIC---\")\n",
    "\n",
    "    # LLM\n",
    "    messages = state[\"messages\"]\n",
    "    model_2 = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "    response = model_2.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def evaluate(state):\n",
    "    \"\"\"\n",
    "    Given a student's submission, a model solution and a rubric, evaluates the submission by assigning scores for each rubric, while giving detailed comments about the correctness, errors and suggestions for improvement in the student code.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages. Agent response should include scores for each rubric, followed by required comments.\n",
    "    \"\"\"\n",
    "    print(\"---EVALUATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model_3 = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o\")\n",
    "    response = model_3.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def review(state):\n",
    "    \"\"\"\n",
    "    Given an evaluation of a student's submission, a model solution and a rubric, reviews the submission and corrects it where necessary.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages.\n",
    "    \"\"\"\n",
    "    print(\"---REVIEW---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model_4 = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o\")\n",
    "    response = model_4.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def extract_marks(state):\n",
    "    \"\"\"\n",
    "    Given an evaluation of a student's submission, a model solution and a rubric, reviews the submission and corrects it where necessary.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages. Agent response should look like: List[int]: List of integers where each integer is the score for a certain rubric.\n",
    "    \"\"\"\n",
    "    print(\"---EXTRACT MARKS---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model_5 = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o\")\n",
    "    response = model_5.invoke(messages)\n",
    "\n",
    "    with open(\"final_evaluations.txt\", \"w\") as file:\n",
    "        # Writing data to a file\n",
    "        file.write(response.content + \"\\n\\n\")\n",
    "\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def calculate_marks(state):\n",
    "    \"\"\"\n",
    "    Given a list of integers of marks, returns sum of marks.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages. Agent response should look like: sum_of_marks (int): The sum of the given marks.\n",
    "    \"\"\"\n",
    "    print(\"---SUM MARKS---\")\n",
    "    messages = state[\"messages\"]\n",
    "    tools = [sum_marks]\n",
    "    model_6 = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o\").bind_tools(tools)\n",
    "    response = model_6.invoke(messages)\n",
    "\n",
    "    with open(\"final_evaluations.txt\", \"a\") as file:\n",
    "        # Writing data to a file\n",
    "        file.write(f\"Final score: {response.content} \\n\\n\")\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "# sum_of_marks = ToolNode([sum_marks])\n",
    "workflow.add_node(\"parse_classes\", parse_classes)  # retrieval\n",
    "workflow.add_node(\"parse_rubric\", parse_rubric)  # Re-writing the question\n",
    "workflow.add_node(\"evaluate\", evaluate)  # retrieval\n",
    "workflow.add_node(\"review\", review)  # retrieval\n",
    "workflow.add_node(\"extract_marks\", extract_marks)  # retrieval\n",
    "workflow.add_node(\"calculate_marks\", calculate_marks)  # retrieval\n",
    "\n",
    "workflow.add_edge(START, \"parse_classes\")\n",
    "workflow.add_edge(\"parse_classes\", \"parse_rubric\")\n",
    "workflow.add_edge(\"parse_rubric\", \"evaluate\")\n",
    "workflow.add_edge(\"evaluate\", \"review\")\n",
    "workflow.add_edge(\"review\", \"extract_marks\")\n",
    "workflow.add_edge(\"extract_marks\", \"calculate_marks\")\n",
    "workflow.add_edge(\"calculate_marks\", END)\n",
    "    \n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---PARSE CLASSES---\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "with open(\"/Users/deepan_roy/Desktop/m24-midsem-install-main/venv_mid_sem_exam/simple_scenario/model_solution.md\", \"r\") as file:\n",
    "    model_solution = file.read()\n",
    "\n",
    "with open(\"/Users/deepan_roy/Desktop/m24-midsem-install-main/venv_mid_sem_exam/simple_scenario/question.md\", \"r\") as file:\n",
    "    question = file.read()\n",
    "\n",
    "with open(\"/Users/deepan_roy/Desktop/m24-midsem-install-main/venv_mid_sem_exam/simple_scenario/rubric.md\", \"r\") as file:\n",
    "    rubric = file.read()\n",
    "\n",
    "with open(\"/Users/deepan_roy/Desktop/m24-midsem-install-main/venv_mid_sem_exam/simple_scenario/student_solution.md\", \"r\") as file:\n",
    "    student_solution = file.read()\n",
    "\n",
    "\n",
    "user_input = f\"Model Solution: {model_solution} \\n\\n\\n Question: {question} \\n\\n\\n Rubric: {rubric} \\n\\n\\n Student Solution: {student_solution}\"\n",
    "stream_graph_updates(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
